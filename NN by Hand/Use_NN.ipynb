{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faeeb511-f5ab-44f0-bec5-821b719f9660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SGD STEP 1 (epoch 0)\n",
      "------------------------------------------------------------\n",
      "Input a^(0) = ['1.000000', '1.000000']\n",
      "Target y    = ['0.000000']\n",
      "\n",
      "FORWARD PASS\n",
      "------------\n",
      "Layer 1 (activation: relu)\n",
      "  Neuron i = 0\n",
      "    z^(1)_0 = sum_j w^(1)_0,j * a^(0)_j + b^(1)_0\n",
      "      w^(1)_0,0 * a^(0)_0 = 0.688844 * 1.000000\n",
      "      w^(1)_0,1 * a^(0)_1 = 0.515909 * 1.000000\n",
      "      + b^(1)_0 = 0.022549\n",
      "    => z^(1)_0 = 1.227302\n",
      "    a^(1)_0 = f_1(z^(1)_0) = relu(1.227302) = 1.227302\n",
      "\n",
      "  Neuron i = 1\n",
      "    z^(1)_1 = sum_j w^(1)_1,j * a^(0)_j + b^(1)_1\n",
      "      w^(1)_1,0 * a^(0)_0 = -0.158857 * 1.000000\n",
      "      w^(1)_1,1 * a^(0)_1 = -0.482166 * 1.000000\n",
      "      + b^(1)_1 = -0.190132\n",
      "    => z^(1)_1 = -0.831155\n",
      "    a^(1)_1 = f_1(z^(1)_1) = relu(-0.831155) = 0.000000\n",
      "\n",
      "Layer 2 (activation: linear)\n",
      "  Neuron i = 0\n",
      "    z^(2)_0 = sum_j w^(2)_0,j * a^(1)_j + b^(2)_0\n",
      "      w^(2)_0,0 * a^(1)_0 = 0.567597 * 1.227302\n",
      "      w^(2)_0,1 * a^(1)_1 = -0.393375 * 0.000000\n",
      "      + b^(2)_0 = -0.046806\n",
      "    => z^(2)_0 = 0.649807\n",
      "    a^(2)_0 = f_2(z^(2)_0) = linear(0.649807) = 0.649807\n",
      "\n",
      "Output a^(L) = ['0.649807']\n",
      "\n",
      "LOSS (Mean Squared Error)\n",
      "-------------------------\n",
      "L = 1/2 * sum_k (a^(L)_k - y_k)^2\n",
      "  k=0: 1/2 * (0.649807 - 0.000000)^2 = 0.211125\n",
      "=> L = 0.211125\n",
      "\n",
      "BACKWARD PASS\n",
      "-------------\n",
      "Output layer (l = 2)\n",
      "  k = 0\n",
      "    dL/da^(L)_0 = a^(L)_0 - y_0 = 0.649807 - 0.000000 = 0.649807\n",
      "    f'(z^(L)_0) = f'(0.649807) = 1.000000\n",
      "    delta^(L)_0 = dL/da^(L)_0 * f'(z^(L)_0) = 0.649807 * 1.000000 = 0.649807\n",
      "\n",
      "Hidden layers\n",
      "Layer l = 1\n",
      "  Neuron j = 0\n",
      "    delta^(1)_0 = f'(z^(1)_0) * sum_k w^(2)_k,0 * delta^(2)_k\n",
      "      w^(2)_0,0 * delta^(2)_0 = 0.567597 * 0.649807\n",
      "      sum_k = 0.368829\n",
      "      f'(z^(1)_0) = f'(1.227302) = 1.000000\n",
      "    => delta^(1)_0 = 1.000000 * 0.368829 = 0.368829\n",
      "  Neuron j = 1\n",
      "    delta^(1)_1 = f'(z^(1)_1) * sum_k w^(2)_k,1 * delta^(2)_k\n",
      "      w^(2)_0,1 * delta^(2)_0 = -0.393375 * 0.649807\n",
      "      sum_k = -0.255618\n",
      "      f'(z^(1)_1) = f'(-0.831155) = 0.000000\n",
      "    => delta^(1)_1 = 0.000000 * -0.255618 = -0.000000\n",
      "\n",
      "GRADIENTS\n",
      "---------\n",
      "Layer 1:\n",
      "  Neuron i = 0\n",
      "    dL/db^(1)_0 = delta^(1)_0 = 0.368829\n",
      "    dL/dw^(1)_0,j = delta^(1)_0 * a^(0)_j\n",
      "      j = 0: 0.368829 * 1.000000 = 0.368829\n",
      "      j = 1: 0.368829 * 1.000000 = 0.368829\n",
      "  Neuron i = 1\n",
      "    dL/db^(1)_1 = delta^(1)_1 = -0.000000\n",
      "    dL/dw^(1)_1,j = delta^(1)_1 * a^(0)_j\n",
      "      j = 0: -0.000000 * 1.000000 = -0.000000\n",
      "      j = 1: -0.000000 * 1.000000 = -0.000000\n",
      "\n",
      "Layer 2:\n",
      "  Neuron i = 0\n",
      "    dL/db^(2)_0 = delta^(2)_0 = 0.649807\n",
      "    dL/dw^(2)_0,j = delta^(2)_0 * a^(1)_j\n",
      "      j = 0: 0.649807 * 1.227302 = 0.797509\n",
      "      j = 1: 0.649807 * 0.000000 = 0.000000\n",
      "\n",
      "UPDATE STEP\n",
      "-----------\n",
      "Learning rate eta = 0.100000\n",
      "w := w - eta * dL/dw\n",
      "b := b - eta * dL/db\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SGD STEP 2 (epoch 0)\n",
      "------------------------------------------------------------\n",
      "Input a^(0) = ['0.000000', '0.000000']\n",
      "Target y    = ['0.000000']\n",
      "\n",
      "FORWARD PASS\n",
      "------------\n",
      "Layer 1 (activation: relu)\n",
      "  Neuron i = 0\n",
      "    z^(1)_0 = sum_j w^(1)_0,j * a^(0)_j + b^(1)_0\n",
      "      w^(1)_0,0 * a^(0)_0 = 0.651961 * 0.000000\n",
      "      w^(1)_0,1 * a^(0)_1 = 0.479026 * 0.000000\n",
      "      + b^(1)_0 = -0.014333\n",
      "    => z^(1)_0 = -0.014333\n",
      "    a^(1)_0 = f_1(z^(1)_0) = relu(-0.014333) = 0.000000\n",
      "\n",
      "  Neuron i = 1\n",
      "    z^(1)_1 = sum_j w^(1)_1,j * a^(0)_j + b^(1)_1\n",
      "      w^(1)_1,0 * a^(0)_0 = -0.158857 * 0.000000\n",
      "      w^(1)_1,1 * a^(0)_1 = -0.482166 * 0.000000\n",
      "      + b^(1)_1 = -0.190132\n",
      "    => z^(1)_1 = -0.190132\n",
      "    a^(1)_1 = f_1(z^(1)_1) = relu(-0.190132) = 0.000000\n",
      "\n",
      "Layer 2 (activation: linear)\n",
      "  Neuron i = 0\n",
      "    z^(2)_0 = sum_j w^(2)_0,j * a^(1)_j + b^(2)_0\n",
      "      w^(2)_0,0 * a^(1)_0 = 0.487846 * 0.000000\n",
      "      w^(2)_0,1 * a^(1)_1 = -0.393375 * 0.000000\n",
      "      + b^(2)_0 = -0.111787\n",
      "    => z^(2)_0 = -0.111787\n",
      "    a^(2)_0 = f_2(z^(2)_0) = linear(-0.111787) = -0.111787\n",
      "\n",
      "Output a^(L) = ['-0.111787']\n",
      "\n",
      "LOSS (Mean Squared Error)\n",
      "-------------------------\n",
      "L = 1/2 * sum_k (a^(L)_k - y_k)^2\n",
      "  k=0: 1/2 * (-0.111787 - 0.000000)^2 = 0.006248\n",
      "=> L = 0.006248\n",
      "\n",
      "BACKWARD PASS\n",
      "-------------\n",
      "Output layer (l = 2)\n",
      "  k = 0\n",
      "    dL/da^(L)_0 = a^(L)_0 - y_0 = -0.111787 - 0.000000 = -0.111787\n",
      "    f'(z^(L)_0) = f'(-0.111787) = 1.000000\n",
      "    delta^(L)_0 = dL/da^(L)_0 * f'(z^(L)_0) = -0.111787 * 1.000000 = -0.111787\n",
      "\n",
      "Hidden layers\n",
      "Layer l = 1\n",
      "  Neuron j = 0\n",
      "    delta^(1)_0 = f'(z^(1)_0) * sum_k w^(2)_k,0 * delta^(2)_k\n",
      "      w^(2)_0,0 * delta^(2)_0 = 0.487846 * -0.111787\n",
      "      sum_k = -0.054535\n",
      "      f'(z^(1)_0) = f'(-0.014333) = 0.000000\n",
      "    => delta^(1)_0 = 0.000000 * -0.054535 = -0.000000\n",
      "  Neuron j = 1\n",
      "    delta^(1)_1 = f'(z^(1)_1) * sum_k w^(2)_k,1 * delta^(2)_k\n",
      "      w^(2)_0,1 * delta^(2)_0 = -0.393375 * -0.111787\n",
      "      sum_k = 0.043974\n",
      "      f'(z^(1)_1) = f'(-0.190132) = 0.000000\n",
      "    => delta^(1)_1 = 0.000000 * 0.043974 = 0.000000\n",
      "\n",
      "GRADIENTS\n",
      "---------\n",
      "Layer 1:\n",
      "  Neuron i = 0\n",
      "    dL/db^(1)_0 = delta^(1)_0 = -0.000000\n",
      "    dL/dw^(1)_0,j = delta^(1)_0 * a^(0)_j\n",
      "      j = 0: -0.000000 * 0.000000 = -0.000000\n",
      "      j = 1: -0.000000 * 0.000000 = -0.000000\n",
      "  Neuron i = 1\n",
      "    dL/db^(1)_1 = delta^(1)_1 = 0.000000\n",
      "    dL/dw^(1)_1,j = delta^(1)_1 * a^(0)_j\n",
      "      j = 0: 0.000000 * 0.000000 = 0.000000\n",
      "      j = 1: 0.000000 * 0.000000 = 0.000000\n",
      "\n",
      "Layer 2:\n",
      "  Neuron i = 0\n",
      "    dL/db^(2)_0 = delta^(2)_0 = -0.111787\n",
      "    dL/dw^(2)_0,j = delta^(2)_0 * a^(1)_j\n",
      "      j = 0: -0.111787 * 0.000000 = -0.000000\n",
      "      j = 1: -0.111787 * 0.000000 = -0.000000\n",
      "\n",
      "UPDATE STEP\n",
      "-----------\n",
      "Learning rate eta = 0.100000\n",
      "w := w - eta * dL/dw\n",
      "b := b - eta * dL/db\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SGD STEP 3 (epoch 0)\n",
      "------------------------------------------------------------\n",
      "Input a^(0) = ['1.000000', '0.000000']\n",
      "Target y    = ['1.000000']\n",
      "\n",
      "FORWARD PASS\n",
      "------------\n",
      "Layer 1 (activation: relu)\n",
      "  Neuron i = 0\n",
      "    z^(1)_0 = sum_j w^(1)_0,j * a^(0)_j + b^(1)_0\n",
      "      w^(1)_0,0 * a^(0)_0 = 0.651961 * 1.000000\n",
      "      w^(1)_0,1 * a^(0)_1 = 0.479026 * 0.000000\n",
      "      + b^(1)_0 = -0.014333\n",
      "    => z^(1)_0 = 0.637627\n",
      "    a^(1)_0 = f_1(z^(1)_0) = relu(0.637627) = 0.637627\n",
      "\n",
      "  Neuron i = 1\n",
      "    z^(1)_1 = sum_j w^(1)_1,j * a^(0)_j + b^(1)_1\n",
      "      w^(1)_1,0 * a^(0)_0 = -0.158857 * 1.000000\n",
      "      w^(1)_1,1 * a^(0)_1 = -0.482166 * 0.000000\n",
      "      + b^(1)_1 = -0.190132\n",
      "    => z^(1)_1 = -0.348989\n",
      "    a^(1)_1 = f_1(z^(1)_1) = relu(-0.348989) = 0.000000\n",
      "\n",
      "Layer 2 (activation: linear)\n",
      "  Neuron i = 0\n",
      "    z^(2)_0 = sum_j w^(2)_0,j * a^(1)_j + b^(2)_0\n",
      "      w^(2)_0,0 * a^(1)_0 = 0.487846 * 0.637627\n",
      "      w^(2)_0,1 * a^(1)_1 = -0.393375 * 0.000000\n",
      "      + b^(2)_0 = -0.100608\n",
      "    => z^(2)_0 = 0.210456\n",
      "    a^(2)_0 = f_2(z^(2)_0) = linear(0.210456) = 0.210456\n",
      "\n",
      "Output a^(L) = ['0.210456']\n",
      "\n",
      "LOSS (Mean Squared Error)\n",
      "-------------------------\n",
      "L = 1/2 * sum_k (a^(L)_k - y_k)^2\n",
      "  k=0: 1/2 * (0.210456 - 1.000000)^2 = 0.311690\n",
      "=> L = 0.311690\n",
      "\n",
      "BACKWARD PASS\n",
      "-------------\n",
      "Output layer (l = 2)\n",
      "  k = 0\n",
      "    dL/da^(L)_0 = a^(L)_0 - y_0 = 0.210456 - 1.000000 = -0.789544\n",
      "    f'(z^(L)_0) = f'(0.210456) = 1.000000\n",
      "    delta^(L)_0 = dL/da^(L)_0 * f'(z^(L)_0) = -0.789544 * 1.000000 = -0.789544\n",
      "\n",
      "Hidden layers\n",
      "Layer l = 1\n",
      "  Neuron j = 0\n",
      "    delta^(1)_0 = f'(z^(1)_0) * sum_k w^(2)_k,0 * delta^(2)_k\n",
      "      w^(2)_0,0 * delta^(2)_0 = 0.487846 * -0.789544\n",
      "      sum_k = -0.385176\n",
      "      f'(z^(1)_0) = f'(0.637627) = 1.000000\n",
      "    => delta^(1)_0 = 1.000000 * -0.385176 = -0.385176\n",
      "  Neuron j = 1\n",
      "    delta^(1)_1 = f'(z^(1)_1) * sum_k w^(2)_k,1 * delta^(2)_k\n",
      "      w^(2)_0,1 * delta^(2)_0 = -0.393375 * -0.789544\n",
      "      sum_k = 0.310587\n",
      "      f'(z^(1)_1) = f'(-0.348989) = 0.000000\n",
      "    => delta^(1)_1 = 0.000000 * 0.310587 = 0.000000\n",
      "\n",
      "GRADIENTS\n",
      "---------\n",
      "Layer 1:\n",
      "  Neuron i = 0\n",
      "    dL/db^(1)_0 = delta^(1)_0 = -0.385176\n",
      "    dL/dw^(1)_0,j = delta^(1)_0 * a^(0)_j\n",
      "      j = 0: -0.385176 * 1.000000 = -0.385176\n",
      "      j = 1: -0.385176 * 0.000000 = -0.000000\n",
      "  Neuron i = 1\n",
      "    dL/db^(1)_1 = delta^(1)_1 = 0.000000\n",
      "    dL/dw^(1)_1,j = delta^(1)_1 * a^(0)_j\n",
      "      j = 0: 0.000000 * 1.000000 = 0.000000\n",
      "      j = 1: 0.000000 * 0.000000 = 0.000000\n",
      "\n",
      "Layer 2:\n",
      "  Neuron i = 0\n",
      "    dL/db^(2)_0 = delta^(2)_0 = -0.789544\n",
      "    dL/dw^(2)_0,j = delta^(2)_0 * a^(1)_j\n",
      "      j = 0: -0.789544 * 0.637627 = -0.503435\n",
      "      j = 1: -0.789544 * 0.000000 = -0.000000\n",
      "\n",
      "UPDATE STEP\n",
      "-----------\n",
      "Learning rate eta = 0.100000\n",
      "w := w - eta * dL/dw\n",
      "b := b - eta * dL/db\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SGD STEP 4 (epoch 0)\n",
      "------------------------------------------------------------\n",
      "Input a^(0) = ['0.000000', '1.000000']\n",
      "Target y    = ['1.000000']\n",
      "\n",
      "FORWARD PASS\n",
      "------------\n",
      "Layer 1 (activation: relu)\n",
      "  Neuron i = 0\n",
      "    z^(1)_0 = sum_j w^(1)_0,j * a^(0)_j + b^(1)_0\n",
      "      w^(1)_0,0 * a^(0)_0 = 0.690478 * 0.000000\n",
      "      w^(1)_0,1 * a^(0)_1 = 0.479026 * 1.000000\n",
      "      + b^(1)_0 = 0.024184\n",
      "    => z^(1)_0 = 0.503210\n",
      "    a^(1)_0 = f_1(z^(1)_0) = relu(0.503210) = 0.503210\n",
      "\n",
      "  Neuron i = 1\n",
      "    z^(1)_1 = sum_j w^(1)_1,j * a^(0)_j + b^(1)_1\n",
      "      w^(1)_1,0 * a^(0)_0 = -0.158857 * 0.000000\n",
      "      w^(1)_1,1 * a^(0)_1 = -0.482166 * 1.000000\n",
      "      + b^(1)_1 = -0.190132\n",
      "    => z^(1)_1 = -0.672298\n",
      "    a^(1)_1 = f_1(z^(1)_1) = relu(-0.672298) = 0.000000\n",
      "\n",
      "Layer 2 (activation: linear)\n",
      "  Neuron i = 0\n",
      "    z^(2)_0 = sum_j w^(2)_0,j * a^(1)_j + b^(2)_0\n",
      "      w^(2)_0,0 * a^(1)_0 = 0.538190 * 0.503210\n",
      "      w^(2)_0,1 * a^(1)_1 = -0.393375 * 0.000000\n",
      "      + b^(2)_0 = -0.021654\n",
      "    => z^(2)_0 = 0.249169\n",
      "    a^(2)_0 = f_2(z^(2)_0) = linear(0.249169) = 0.249169\n",
      "\n",
      "Output a^(L) = ['0.249169']\n",
      "\n",
      "LOSS (Mean Squared Error)\n",
      "-------------------------\n",
      "L = 1/2 * sum_k (a^(L)_k - y_k)^2\n",
      "  k=0: 1/2 * (0.249169 - 1.000000)^2 = 0.281874\n",
      "=> L = 0.281874\n",
      "\n",
      "BACKWARD PASS\n",
      "-------------\n",
      "Output layer (l = 2)\n",
      "  k = 0\n",
      "    dL/da^(L)_0 = a^(L)_0 - y_0 = 0.249169 - 1.000000 = -0.750831\n",
      "    f'(z^(L)_0) = f'(0.249169) = 1.000000\n",
      "    delta^(L)_0 = dL/da^(L)_0 * f'(z^(L)_0) = -0.750831 * 1.000000 = -0.750831\n",
      "\n",
      "Hidden layers\n",
      "Layer l = 1\n",
      "  Neuron j = 0\n",
      "    delta^(1)_0 = f'(z^(1)_0) * sum_k w^(2)_k,0 * delta^(2)_k\n",
      "      w^(2)_0,0 * delta^(2)_0 = 0.538190 * -0.750831\n",
      "      sum_k = -0.404090\n",
      "      f'(z^(1)_0) = f'(0.503210) = 1.000000\n",
      "    => delta^(1)_0 = 1.000000 * -0.404090 = -0.404090\n",
      "  Neuron j = 1\n",
      "    delta^(1)_1 = f'(z^(1)_1) * sum_k w^(2)_k,1 * delta^(2)_k\n",
      "      w^(2)_0,1 * delta^(2)_0 = -0.393375 * -0.750831\n",
      "      sum_k = 0.295358\n",
      "      f'(z^(1)_1) = f'(-0.672298) = 0.000000\n",
      "    => delta^(1)_1 = 0.000000 * 0.295358 = 0.000000\n",
      "\n",
      "GRADIENTS\n",
      "---------\n",
      "Layer 1:\n",
      "  Neuron i = 0\n",
      "    dL/db^(1)_0 = delta^(1)_0 = -0.404090\n",
      "    dL/dw^(1)_0,j = delta^(1)_0 * a^(0)_j\n",
      "      j = 0: -0.404090 * 0.000000 = -0.000000\n",
      "      j = 1: -0.404090 * 1.000000 = -0.404090\n",
      "  Neuron i = 1\n",
      "    dL/db^(1)_1 = delta^(1)_1 = 0.000000\n",
      "    dL/dw^(1)_1,j = delta^(1)_1 * a^(0)_j\n",
      "      j = 0: 0.000000 * 0.000000 = 0.000000\n",
      "      j = 1: 0.000000 * 1.000000 = 0.000000\n",
      "\n",
      "Layer 2:\n",
      "  Neuron i = 0\n",
      "    dL/db^(2)_0 = delta^(2)_0 = -0.750831\n",
      "    dL/dw^(2)_0,j = delta^(2)_0 * a^(1)_j\n",
      "      j = 0: -0.750831 * 0.503210 = -0.377826\n",
      "      j = 1: -0.750831 * 0.000000 = -0.000000\n",
      "\n",
      "UPDATE STEP\n",
      "-----------\n",
      "Learning rate eta = 0.100000\n",
      "w := w - eta * dL/dw\n",
      "b := b - eta * dL/db\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from neural_network import NeuralNetwork\n",
    "\n",
    "# 1.  (2 inputs, 2 hidden neurons in one hidden layer, 1 output)\n",
    "layer_sizes = [2, 2, 1]\n",
    "activation_names = [\"ReLU\", \"linear\"]   # same activation in all layers\n",
    "nn = NeuralNetwork(layer_sizes, activation_names, random_seed=0)\n",
    "\n",
    "# 2. training data\n",
    "training_data = [\n",
    "    ([0.0, 0.0], [0.0]),\n",
    "    ([0.0, 1.0], [1.0]),\n",
    "    ([1.0, 0.0], [1.0]),\n",
    "    ([1.0, 1.0], [0.0]),\n",
    "]\n",
    "\n",
    "# 3. training step\n",
    "nn.train_sgd(\n",
    "    training_data=training_data,\n",
    "    epochs=1,\n",
    "    learning_rate=0.1,\n",
    "    print_every=1,\n",
    "    print_math=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5a49b-0e06-4d44-b912-6c076caadabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
